import argparse
import pathlib

import h5py
import matplotlib.pyplot as plt
from matplotlib.ticker import MaxNLocator

import numpy as np


HDF5_EXTENSION    = ".h5"
PROJECT_ROOT_PATH = pathlib.Path(__file__).parent.parent.resolve().parent
RESULTS_PATH      = PROJECT_ROOT_PATH / 'share' / 'Experiments' / 'Results'
assert RESULTS_PATH.exists() and \
       RESULTS_PATH.is_dir(), \
      "Cannot find Experiments/Results directory: {RESULTS_PATH}"
FIGURES_PATH      = PROJECT_ROOT_PATH / 'share' / 'Experiments' / 'Figures'


def accuracy(true_positive: int,  true_negative: int,
             false_positive: int, false_negative: int) -> float:
    """
    Returns the accuracy value for the given confusion matrix.
    """
    return (true_positive + true_negative) / float(true_positive + false_positive + true_negative + false_negative)


def precision(true_positive: int, false_positive: int) -> float:
    """
    Returns the precision value for the given confusion matrix.
    """
    return true_positive / float(true_positive + false_positive)


def arr_accuracy(arr: np.ndarray):
    """
    Calls the `accuracy` function on the input array.
    """
    return accuracy(arr[0], arr[1], arr[2], arr[3])


def arr_precision(arr: np.ndarray):
    """
    Calls the `precision` function on the input array.
    """
    return precision(arr[0], arr[2])


def get_metric_group(hdf5_path: pathlib.Path) -> h5py.Group:
    """
    Opens an HDF5 file and access the location of the Metic group.
    """
    h5_file  = h5py.File(hdf5_path, "r")
    return h5_file["Metric"]


def get_figures(part: str, policy: str, reconstructions: list[str]) -> list[tuple[plt.Figure, plt.Axes, plt.Axes]]:
    """
    Returns multiple matplotlib figures with different titles.
    """
    plots = []
    for label in reconstructions:
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=[12.8, 6.4], dpi=200)

        fig_title = f"{label} Reconstruction of {part} using {policy}".replace("_", " ")
        fig.suptitle(fig_title)

        ax1.set_title("Reconstruction Accuracy")
        ax1.set_xlabel("Views Added")
        ax1.set_ylim(0, 1.1)
        ax2.set_title("Reconstruction Precision")
        ax2.set_xlabel("Views Added")
        ax2.set_ylim(0, 1.1)

        plots.append((fig, ax1, ax2))
    return plots


def select_experiment() -> pathlib.Path:
    """
    Selects one from the possible experiment directories.
    """
    experiments = [x for x in RESULTS_PATH.iterdir() if x.is_dir()]
    if len(experiments) == 0:
        print("No experiment directories available")
    elif len(experiments) == 1:
        return experiments[0]

    print("Please select which experiment directory to use:")
    for i, experiment in enumerate(experiments):
        print(f"[{i}] {experiment.name}")
    idx = int(input("Enter experiment number: "))
    return experiments[idx]


def plot_policy_sweep(policy_path: pathlib.Path):
    """
    Generates the accuracy and precision plots. Combines the multiple policy view into one plot and
    if the policy was repeated then it plots the min/max and average with standard deviation bars.
    The generated figure is then saved.
    """

    confusion_groups = ["OccupancyConfusion_TSDF", "OccupancyConfusion_binary", "OccupancyConfusion_probability"]
    confusion_grid_labels = ["TSDF", "Space Carving", "Occupation Probability"]
    n_group = len(confusion_groups)

    part_name   = policy_path.parent.name.capitalize()
    policy_name = policy_path.name
    plots = get_figures(part_name, policy_name, confusion_grid_labels)

    try:
        # Sort in increasing order on integer number.
        views_dirs = sorted([x for x in policy_path.iterdir() if x.is_dir()],
                            key=lambda x: int(str(x.name)), reverse=True)
    except ValueError:
        print("Could not turn directory name into integer for the number of views generated by the policy.")
        raise

    for views in views_dirs:
        line_label = f"{views.name} Views"

        views_plus_one = 1 + int(views.name)
        xdata = list(range(views_plus_one))

        reps_dirs = [x for x in views.iterdir() if x.is_dir()]
        data = [ np.zeros((int(views.name), 4, len(reps_dirs))) ] * n_group
        acc  = [ np.zeros((views_plus_one, len(reps_dirs)))     ] * n_group
        pre  = [ np.zeros((views_plus_one, len(reps_dirs)))     ] * n_group

        for i, reps in enumerate(reps_dirs):
            hdf5_dir = reps / "results.h5"
            metric_group = get_metric_group(hdf5_dir)
            for g, group in enumerate(confusion_groups):
                confusion_group = metric_group[group]
                data[g][:, :, i] = confusion_group.get("data")[:, 1:5]
                acc[g][1:, i]    = np.apply_along_axis(arr_accuracy,  1, data[g][:, :, i])
                pre[g][1:, i]    = np.apply_along_axis(arr_precision, 1, data[g][:, :, i])

        if len(reps_dirs) > 1:
                line_label += " (Average)"
        for g in range(n_group):
            if len(reps_dirs) > 1:
                acc_avg = acc[g].mean(axis=1)
                acc_std = acc[g].std(axis=1)
                acc_min = acc[g].min(axis=1)
                acc_max = acc[g].max(axis=1)
                plots[g][1].errorbar(xdata, acc_avg, acc_std, linewidth=2, label=line_label, elinewidth=1, alpha=0.75, capsize=4.5)
                plots[g][1].fill_between(xdata, acc_min, acc_max, alpha=0.2)

                pre_avg = pre[g].mean(axis=1)
                pre_std = pre[g].std(axis=1)
                pre_min = pre[g].min(axis=1)
                pre_max = pre[g].max(axis=1)
                plots[g][2].errorbar(xdata, pre_avg, pre_std, linewidth=2, label=line_label, elinewidth=1, alpha=0.75, capsize=4.5)
                plots[g][2].fill_between(xdata, pre_min, pre_max, alpha=0.2)
            else:
                plots[g][1].plot(xdata, acc[g][:, 0], linewidth=2, label=line_label)
                plots[g][2].plot(xdata, pre[g][:, 0], linewidth=2, label=line_label)

    image_fpath_root = (FIGURES_PATH / policy_path.relative_to(RESULTS_PATH)).parent
    for g in range(n_group):
        plots[g][1].legend(loc='lower right')
        plots[g][2].legend(loc='lower right')

        plots[g][1].xaxis.set_major_locator(MaxNLocator(integer=True))
        plots[g][1].yaxis.set_ticks([0.2, 0.4, 0.6, 0.8, 1.0])
        plots[g][2].xaxis.set_major_locator(MaxNLocator(integer=True))
        plots[g][2].yaxis.set_ticks([0.2, 0.4, 0.6, 0.8, 1.0])

        image_fpath = image_fpath_root / confusion_grid_labels[g]
        # Split the old path to get the location of the figure.
        if image_fpath.exists() is False:
            image_fpath.mkdir(parents=True)
        image_fpath /= policy_path.name + "_Results.png"

        plots[g][0].savefig(image_fpath)
        plt.close(plots[g][0])



def main(_: argparse.Namespace) -> None:
    """
    Program entry point.
    """
    experiment_dir = select_experiment()
    shape_dirs = [x for x in experiment_dir.iterdir() if x.is_dir()]
    for shape in shape_dirs:
        policy_dirs = [x for x in shape.iterdir() if x.is_dir()]
        for policy in policy_dirs:
            plot_policy_sweep(policy)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        prog='Plot Experiment Result Confusion',
        description='This script iterates through a set of experiment results (generated by the '
                    'sweep_run_experiment.py script) and creates condensed accuracy and precision '
                    'results for a policy reconstructing a specific shape.'
    )

    args = parser.parse_args()
    try:
        main(args)
    except KeyboardInterrupt as e:
        print("\nExiting early on KeyboardInterrupt.")
