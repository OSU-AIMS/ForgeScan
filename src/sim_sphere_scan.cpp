#include <ForgeScan/sim_sensor_reading.h>
#include <ForgeScan/voxel_grid.h>

#include <Eigen/Geometry>

#include <iostream>

#include <string>
#include <random>
#include <math.h>


/// Camera on a sphere is 2.5 m away from world-origin.
#define SIM_RHO 2.5

/// Detected sphere has radius of 0.75 m, centered at world-origin.
#define SPHERE_RHO 0.75

/// How wide of a sample the sensor gets of the detected sphere.
/// Rather than sensor FOV, this makes more sense.
#define SAMPLE_MAX_PHI (M_PI / 2.5)


/// @brief Samples points along a sphere and records each point inside the scanner's sensor attribute
/// @param scanner Sensor to add points to; number of points to add is inferred by the scanner array dimensions
/// @warning This a bit of a hack. The sensor's frame relative to the world is not well defined. 
///          There may be mirroring issues, beware.
/// @note Uses proper uniform random sampling from a sphere. For more, see:
///           http://corysimon.github.io/articles/uniformdistn-on-sphere/
void sample_sphere_to_sensor(SimSensorReading* scanner);


/// @brief Generates new camera pose view which faces the origin by randomly sampling points
/// @param position Cartesian location of the camera
/// @param normal Sensor Z-direction
/// @note Uses proper uniform random sampling from a sphere. For more, see:
///           http://corysimon.github.io/articles/uniformdistn-on-sphere/
void random_sample_camera_pose(Eigen::Vector3d& position, Eigen::Vector3d& normal);


/// @brief Generates a new camera pose which facing the origin in an ordered, uniform manner.
/// @param position Cartesian location of the camera
/// @param normal Sensor Z-direction
/// @param num_views Requires the number of views. Function has a static counter to track the number of
///                  times it has been called. Must be greater than 2 for the sequence to function.
/// @note Base on Fibonacci sphere sequence. See:
///           https://stackoverflow.com/questions/9600801/
/// @note If the number of views requested if 1 or below this is set to 2.
/// @warning The manner in which #num_views is stored means this is not robust if it is used in
///          multiple locations across a program.
void uniform_sample_camera_pose(Eigen::Vector3d& position, Eigen::Vector3d& normal, const int& num_view);


/// @brief   Simulates the scanning of a sphere by a narrow FOV laser scanner. 
/// @param num_pts   Positive, integer number of points to add to the sensor. Default 1000.
/// @param num_view  Positive, integer number of views to add. Default 10.
/// @param first_pos If true will set the first view to be fixed down the world +Z axis. Default `true`.
/// @param random_pose If true will randomly sample new poses. If false will uniformly distribute each pose.
///                    Default `false`.
/// @details The scanner is a hack. Only one "true" scan is generated. The rest of the view come from this scan
///          being transformed around the space. We can do this because the sphere is uniform and the scanner's
///          radius is held constant. 
///          The one sample is generated by sampling the sphere while limiting phi. These points are transformed to
///          the sensor perspective. It is important to realize that this means the sensor ONLY sees the sphere. This
///          leads to poor results when attempting reconstruction.
///          However, the goal of this demo script is to demonstrate that this addition of multiple sensors is possible
///          and can create a uniform VoxelGrid of a part. So despite the limitations, this is a useful proof of concept.
int main(int argc, char* argv[])
{
    int num_pts = 1000, num_view = 10;
    bool first_pos = true, random_pose = false;
    if (argc >= 2) num_pts  = std::abs( std::stoi(argv[1]) );  // Set the number of sensor points
    if (argc >= 3) num_view = std::abs( std::stoi(argv[2]) );  // Set the number of sensors
    if (argc >= 4) first_pos = (argv[4] == "true");            // If true, sets first view to be fixed down the world +Z axis
    if (argc >= 4) random_pose = (argv[5] == "true");          // If true, will use a random sampling strategy
    std::cout << "Running for " << num_view << " sensors with " << num_pts << " samples each." << std::endl;

    // Set up the VoxelGrid 
    Eigen::Vector3d lower(-1, -1, -1), upper(1, 1, 1);

    double res = 0.02;

    // 2m x 2m x 2m cube with 0.02 m resolution
    VoxelGrid grid(res, lower, upper, false);


    // Set up the simulated sensor
    Eigen::Vector3d position, normal;
    SimSensorReading laser_scan(position, normal, num_pts);
    sample_sphere_to_sensor(&laser_scan);  // Populate the sensor


    // Optional deterministic first view
    // This is positioned along the +Z axis, facing the origin.
    if (first_pos)
    {
        laser_scan.position << 0, 0, SIM_RHO;
        laser_scan.normal << 0, 0, -1;
        grid.add_sensor(laser_scan);

        // std::cout << "\nAdding first scanner at: \n" << laser_scan.position.transpose() << std::endl;
        // std::cout << "With normal of: \n" << laser_scan.normal.transpose() << std::endl;

        std::cout << "Added deterministic first view." << std::endl;
        --num_view;  // Decrement the number of requested views for the rest of the program
    }

    std::string strategy = random_pose ? "random" : "uniform";
    std::cout << "Adding " << num_view << " new views. Using a " + strategy + " strategy" << std::endl;
    for (int i = 0; i < num_view; ++i)
    {
        uniform_sample_camera_pose(position, normal, num_view);
        // random_sample_camera_pose(position, normal);
        laser_scan.position << position;
        laser_scan.normal << normal;

        // std::cout << "\nAdding scanner at: \n" << laser_scan.position.transpose() << std::endl;
        // std::cout << "With normal of: \n" << laser_scan.normal.transpose() << std::endl;
        grid.add_sensor(laser_scan);
    }
    std::string fname = "sim_sphere_scan";
    grid.saveXDMF(fname);
    std::cout << "Complete! Saved file as: " + fname << std::endl;
    return 0;
}


void sample_sphere_to_sensor(SimSensorReading* scanner)
{
    static std::random_device rd;
    static std::mt19937 gen(rd());
    static std::uniform_real_distribution<> dist(0, 1);

    static float max_theta = 2 * M_PI;               // 0 - 360 degrees in theta (angle from the positive X-axis)
    static float phi_scale = SAMPLE_MAX_PHI / M_PI;  // Scales uniform to what percentage of the max it may be


    // Set scanner position to be alignment the positive Z-axis, pointing down
    scanner->position << 0, 0, SIM_RHO;
    scanner->normal   << 0, 0, -1;

    float x, y, z, theta, phi, sin_phi;
    int n_pts = scanner->n * scanner->m;
    for (int i = 0; i < n_pts; ++i) {
        theta = max_theta * dist(gen);
        phi = std::acos(1 - 2 * dist(gen) * phi_scale);

        sin_phi = std::sin(phi);
        y = std::sin(theta) * sin_phi * SPHERE_RHO;
        x = std::cos(theta) * sin_phi * SPHERE_RHO;
        z = std::cos(phi) * SPHERE_RHO;

        scanner->sensor.row(i) << x, y, z;
        // std::cout << "\n[" << i << "]" << "Point located at:\n" << scanner->sensor.row(i) << std::endl;

        scanner->sensor.row(i) -= scanner->position;
        scanner->sensor.row(i)(1) *= -1;  // Mirrors Y for reference frame change from global to the sensor's.
        scanner->sensor.row(i)(2) *= -1;  // Mirrors Z for the same reason.
        // std::cout << "[" << i << "]" << "Saved sensor point at:\n" << scanner->sensor.row(i) << std::endl;
    }
}


void random_sample_camera_pose(Eigen::Vector3d& position, Eigen::Vector3d& normal)
{
    static std::random_device rd;
    static std::mt19937 gen(rd());
    static std::uniform_real_distribution<> dist(0, 1);

    static const Eigen::Vector3d world_origin(0, 0, 0);
    static const float max_theta = 2 * M_PI;  // 0 - 360 degrees in theta (angle from the positive X-axis)
    static const float max_phi = M_PI;        // 0 - 180 degrees in phi (angle from positive Z-axis)


    float x, y, z, theta, phi, sin_phi;

    theta = max_theta * dist(gen);
    phi = std::acos(1 - 2 * dist(gen));

    sin_phi = std::sin(phi);
    y = std::sin(theta) * sin_phi * SIM_RHO;
    x = std::cos(theta) * sin_phi * SIM_RHO;
    z = std::cos(phi) * SIM_RHO;

    position << x, y, z;

    normal = world_origin - position;
    normal.normalize();
}


void uniform_sample_camera_pose(Eigen::Vector3d& position, Eigen::Vector3d& normal, const int& num_view)
{
    static const Eigen::Vector3d world_origin(0, 0, 0);
    static size_t count = 0;
    static double x = 0, y = 0, z = 0, r = 0, theta = 0;
    static double adj_num_view = num_view > 1 ? num_view - 1 : 1;
    static double phi = M_PI - (3 - std::sqrt(5));

    // Core calculations
    y = 1 - (count / (adj_num_view)) * 2;
    r = std::sqrt(1 - y*y);
    theta = phi * count;
    x = std::cos(theta) * r;
    z = std::sin(theta) * r;

    // Update position and normal
    position << x, y, z;
    position *= SIM_RHO;

    normal = world_origin - position;
    normal.normalize();
    // std::cout << "[" << count << "] Position and normal:\n\t" << position.transpose() << "\n\t" << normal.transpose() << std::endl;
    
    // Increment count before returning
    ++count;
}
